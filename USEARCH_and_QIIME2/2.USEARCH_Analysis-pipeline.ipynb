{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VWBPRGbanner.jpeg](VWBPRGbanner.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16S amplicon NGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USEARCH Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input**\n",
    "\n",
    "Raw `fastq` files from illumina NGS platforms.\n",
    "\n",
    "**Output**\n",
    "\n",
    "Complied OTU table (taxonomy not assigned) and final OTU sequences in `fasta` format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumptions**\n",
    "\n",
    "- Working within MacOS environment - there are slight differences when working within a linux environment. If you are using a Pawsey virtual machine (Nimbus) then you will need to work within a linux environment. The documentation for usearch is the same for MacOS and linux with the exception that you will need to download the linux versions, however take note it is primarily written for MacOS and some features may not be available. Please provide feedback if functions are not working within a linux environment.\n",
    "- Downloaded USEARCH. This pipeline requires USEARCH 8, 9.2 and 10. In most cases the 34-bit files are okay, however if undertaking analysis of large datasets you will need to purchase the 64-bit. The Cryptick lab has the 64-bit versions of USEARCH8, 9.2 and 10 - you will need to use the iMac to access these. Unfortunately we only have the 64-bit version of USEARCH9.2 on a linux environment, however this is sufficent for almost all steps. You will have to weight up your options between running the analysis on Nimbus vs iMac. You might consider doing the first steps on the Nimbus cloud and the final steps (i.e. UNOISE clustering) on the iMac."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data type**\n",
    "\n",
    "This analysis is for paired-end reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using this pipeline**\n",
    "\n",
    "I strongly suggest you take a small sub-set of your data though the pipeline outlined below step-by-step first to get an understanding of what each command is doing. Importantly it will also allow to explore the influence of the different variables on your dataset. \n",
    "\n",
    "Once you are happy with the parameters and that the script is working you can use the full script to analyse all your samples.\n",
    "\n",
    "Simply edit the script with your parameters, and save it in a directory with your raw fastq files.\n",
    "\n",
    "In a `bash` terminal navigate to your directory and perform the following to execute the script and save the terminal output to a text file.\n",
    "\n",
    "    cd /Users/name/Documents/NGS-Analysis\n",
    "\n",
    "    chmod +x this_script.sh\n",
    "    \n",
    "    ./this_script.sh > 16S-NGS-usearch-output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastq info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[fastq_info command](https://www.drive5.com/usearch/manual/cmd_fastx_info.html)\n",
    "\n",
    "This commands gives a short summary report of the sequences in a `fasta` or `fastq` file. It is useful for a first check on what is in a new file. The report is written to the console and can be saved to a text file using the -output option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "raw_data=\"raw_data\"\n",
    "read_summary=\"1.read_summary\"\n",
    "usearch=\"usearch10\"\n",
    "\n",
    "\n",
    "mkdir $read_summary\n",
    "\n",
    " for fq in $raw_seqs/*R1*.fastq\n",
    " do\n",
    "  $usearch -fastx_info $fq -output $read_summary/1a_fwd_fastq_info.txt\n",
    " done\n",
    "\n",
    " for fq in $raw_seqs/*R2*.fastq\n",
    " do\n",
    "  $usearch -fastx_info $fq -output $read_summary/1b_rev_fastq_info.txt\n",
    " done\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at just one fasta or fastq files, for example inspect your concatenate dereplicated sequences.\n",
    "The `-secs 5` options is good when just wanting a snap shot of a large sequences files, however can be deleted if you can it to scan the entire file.\n",
    "\n",
    "```bash\n",
    "usearch10 -fastx_info sequences.fastq -secs 5 -output reads_info.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** IMPORTANT! **\n",
    "\n",
    "At this point it is important to look at the 'EE' value which means expected error.\n",
    "\n",
    "Detailed information on this can be found [here](https://www.drive5.com/usearch/manual/exp_errs.html).\n",
    "\n",
    "In short you want your EE value to be under 2, usually it is lower for the forward reads than the reverse reads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[fastq_mergepairs command](https://www.drive5.com/usearch/manual/cmd_fastq_mergepairs.html)\n",
    "\n",
    "This command merges paired-end reads to create consensus sequences and, optionally, consensus quality scores. This command has many features and options so I recommend spending some time browsing the documentation to get familiar with the capabilities of fastq_mergepairs and issues that arise in read merging.\n",
    "\n",
    "As is the convention for illumina paried reads the forward sequences are labeled `samplename_SXX_L001_R1_001.fastq` and reverse sequences labeled `samplename_SXX_L001_R2_001.fastq`.\n",
    "\n",
    "There are many additional options for this command that are specified [here](https://www.drive5.com/usearch/manual/merge_options.html), and a thorough outline of reviewing fastq_mergepairs reports [here](https://www.drive5.com/usearch/manual/merge_report.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "raw_data=\"raw_data\"\n",
    "merged_reads=\"2.merged_reads\"\n",
    "usearch9=\"usearch9.2\"\n",
    "usearch8=\"usearch8\"\n",
    "# Maximum no of mismatches in the alignment - Default 5. Consider increasing if you have long overlaps.\n",
    "maxdiffs=\"15\"\n",
    "# Discard pair if alugnment is shorter than this value - Default 16 bp\n",
    "overlap=\"50\"\n",
    "\n",
    "mkdir ${merged_reads}\n",
    "mkdir working1\n",
    "\n",
    "#*****************************************************************************************\n",
    "# Step1: merge data with usearch9 -fastq-filter\n",
    "\n",
    "for file1 in ${raw_data}/*R1_001.fastq\n",
    "    do\n",
    "\n",
    "        echo \"\"\n",
    "        echo ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        echo Merging paired reads\n",
    "        echo forward reads are:\n",
    "        echo $(basename ${file1})\n",
    "        echo reverse reads are:\n",
    "        echo $(basename ${file1} R1_001.fastq)R2_001.fastq\n",
    "\n",
    "    $usearch -fastq_mergepairs ${file1} -reverse \"${raw_data}/$(basename -s R1_001.fastq ${file1})R2_001.fastq\" -fastqout \"working1/$(basename \"$file1\")\" -fastq_maxdiffs ${maxdiffs} -fastq_minovlen ${overlap} -report ${merged_data}/2a_merging_seqs_report.txt -tabbedout ${merged_data}/2b_tabbedout.txt\n",
    "done\n",
    "\n",
    "#*****************************************************************************************\n",
    "# Step 2: Remove \"_L001_R1_001\" from filenames\n",
    "\n",
    "for file2 in working1/*.fastq\n",
    "    do\n",
    "\n",
    "        rename=\"$(basename ${file2} _L001_R1_001.fastq).fastq\"\n",
    "\n",
    "        mv ${file2} ${merged_data}/${rename}\n",
    "done\n",
    "\n",
    "#*****************************************************************************************\n",
    "# Removing working directory\n",
    "\n",
    "        rm -r working1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Note**_\n",
    "\n",
    "There are a number of other commands that you may find useful at this step available on the USEARCH documenation page [here](https://www.drive5.com/usearch/manual/merge_options.html). \n",
    "After trials with tick NGS data I have found that in most cases altering these parameters make little to no difference to the outcome of the sequences (i.e % merged) and hence they are obmitted from this pipeline - _however the two exceptions_ are `fastq_minovlen` and `fastq-maxdiffs`. \n",
    "\n",
    "Again it is important to remember the purpose of this line of code, it is simply to merge the forward and reverse sequences **not** to act as a quality control step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality control and removing dimer sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[fastq_filter command](https://www.drive5.com/usearch/manual/cmd_fastq_filter.html)\n",
    "\n",
    "This command performs quality filtering and converts `fastq` files to `fasta` format. Again there are a number of filtering options available with this command that you can explore, however below are the most approriate for 16S amplicon NGS data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```bash\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# This script works with usearch9.2 and usearch10\n",
    "# fastq_filter provides a quiality filter and max ee rate \n",
    "\n",
    "merged_reads=\"2.merged_reads\"\n",
    "QF_reads=\"3.quality_filtered\"\n",
    "# Usearch executable\n",
    "usearch=\"usearch10\"\n",
    "# Enter % expected error rate threchold for seq quality filtering (1% = 0.01)\n",
    "error_rate=\"0.01\"\n",
    "# Enter min length of sequence for trimming in bp (eg. to keep all seqs above 200 bp enter \"200\")\n",
    "minlen=\"150\"\n",
    "\n",
    "mkdir ${QF_reads}\n",
    "\n",
    "for file3 in ${merged_reads}/*.fastq\n",
    "    do\n",
    "        echo \"\"\n",
    "        echo ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        echo Quality control and removing dimer seqs\n",
    "        echo input is:\n",
    "        echo ${file3}\n",
    "\n",
    "    $usearch -fastq_filter ${file3} -fastaout \"$QF_reads/$(basename \"$file3\" .fastq).fasta\" -fastq_maxee_rate ${error_rate} -fastq_minlen ${minlen}\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Trim primers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usearch 9.2 [search_oligodb command](https://www.drive5.com/usearch/manual/cmd_search_oligodb.html)\n",
    "\n",
    "This command searches for matches of nucleotide sequences to a database containing short nucleotide sequences (oligonucleotides). In this context the command is used to search for matches to primers. By default, -maxdiffs 2 is assumed and other accept criteria are not used.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "usearch8 [search_pcr command](https://www.drive5.com/usearch/manual8.1/cmd_search_pcr.html)\n",
    "\n",
    "This command searches for predicted amplicons. The sequences specific for each primer are made into a fasta files (databases). Each query sequence is searched for matches to a pair of primers that would generate a PCR amplicon. The `-pcr_strip_primers` command is then used to strip the primers from each sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```bash\n",
    "usearch9=\"usearch9.2\"\n",
    "usearch8=\"usearch9\"\n",
    "\n",
    "QF=\"3.quality_filtered\"\n",
    "trimmed_data=\"4.trimmed_data\"\n",
    "seqs_w_fwd_primer=\"5.seqs_w_fwd_primer\"\n",
    "seqs_wo_fwd_primer=\"6.seqs_wo_fwd_primer\"\n",
    "seqs_w_fwd_and_rev_primer=\"7.seqs_w_fwd_and_rev_primer\"\n",
    "seqs_w_fwd_butnot_rev_primer=\"8.seqs_w_fwd_butnot_rev_primer\"\n",
    "# Enter FWD primer sequence 5'-3' (degenerate bases OK)\n",
    "fwd_primer=\"AGAGTTTGATCCTGGCTYAG\"\n",
    "# Enter REV primer sequence 5'-3' (degenerate bases OK)\n",
    "rev_primer=\"TGCTGCCTCCCGTAGGAGT\"\n",
    "# Enter number of primer mismatched allowed\n",
    "pcr_missmatches=\"0\"\n",
    "\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "echo Triming primers and distal bases\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "echo \"\"\n",
    "\n",
    "# At the moment this usearch command can only take .fasta as input so can only be done\n",
    "# after QF\n",
    "\n",
    "# Creating working directories\n",
    "\n",
    "mkdir ${trimmed_data}\n",
    "mkdir ${seqs_w_fwd_primer}\n",
    "mkdir ${seqs_wo_fwd_primer}\n",
    "mkdir ${seqs_w_fwd_and_rev_primer}\n",
    "mkdir ${seqs_w_fwd_butnot_rev_primer}\n",
    "\n",
    "# Creating FWD primer db\n",
    "\n",
    "        echo \">fwd_primer\" > fwd_primer_db.fasta\n",
    "        echo ${fwd_primer} >> fwd_primer_db.fasta\n",
    "\n",
    "# Creating REV primer db\n",
    "\n",
    "        echo \">rev_primer\" > rev_primer_db.fasta\n",
    "        echo ${rev_primer} >> rev_primer_db.fasta\n",
    "\n",
    "# Creating FWD and REV primer db\n",
    "    \n",
    "        echo \">fwd_primer\" > both_primers_db.fasta\n",
    "        echo ${fwd_primer} >> both_primers_db.fasta\n",
    "        echo \">rev_primer\" >> both_primers_db.fasta\n",
    "        echo ${rev_primer} >> both_primers_db.fasta\n",
    "\n",
    "#*****************************************************************************************\n",
    "# Step 1: Finding seqs with FWD primer\n",
    "\n",
    "for file4 in ${QF}/*.fasta\n",
    "    do\n",
    "\n",
    "        echo \"\"\n",
    "        echo ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        echo Trimming primers step 1: finding seqs with FWD primer\n",
    "        echo input is:\n",
    "        echo ${file4}\n",
    "\n",
    "    $usearch9 -search_oligodb ${file4} -db fwd_primer_db.fasta -strand both -matched \"${seqs_w_fwd_primer}/$(basename ${file4})\" -notmatched \"${seqs_wo_fwd_primer}/$(basename ${file4})\"\n",
    "done\n",
    "#*****************************************************************************************\n",
    "# Step 2: Finding seqs with FWD and REV primers\n",
    "\n",
    "for file5 in ${seqs_w_fwd_primer}/*.fasta\n",
    "    do\n",
    "\n",
    "        echo \"\"\n",
    "        echo ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        echo Trimming primers step 2: finding seqs with FWD and REV primer\n",
    "        echo input is:\n",
    "        echo ${file5}\n",
    "\n",
    "    $usearch9 -search_oligodb ${file5} -db rev_primer_db.fasta -strand both -matched \"${seqs_w_fwd_and_rev_primer}/$(basename ${file5})\" -notmatched \"${seqs_w_fwd_butnot_rev_primer}/$(basename ${file5})\"\n",
    "done\n",
    "#*****************************************************************************************\n",
    "# Step 3: Trimming FWD and REV primers\n",
    "\n",
    "for file6 in ${seqs_w_fwd_and_rev_primer}/*.fasta\n",
    "    do\n",
    "\n",
    "        echo \"\"\n",
    "        echo ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        echo Trimming primers step 3: removing FWD and REV primers\n",
    "        echo input is:\n",
    "        echo ${file6}\n",
    "\n",
    "    $usearch8 -search_pcr ${file6} -db both_primers_db.fasta -strand both -maxdiffs ${pcr_missmatches} -pcr_strip_primers -ampout \"${trimmed_data}/$(basename ${file6} .fasta).fasta\"\n",
    "done\n",
    "\n",
    "#*****************************************************************************************\n",
    "# Removing working directories\n",
    "\n",
    "# rm -r seqs_w_fwd_primer\n",
    "# rm -r seqs_wo_fwd_primer\n",
    "# rm -r seqs_w_fwd_and_rev_primer\n",
    "# rm -r seqs_w_fwd_butnot_rev_primer\n",
    "\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "## Renaming sequences\n",
    "\n",
    "There are no usearch commands or other parameters in this step, it is simply a series of bash commands to ensure the sequence labels are compatable for downstream OTU/ZOTU clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```bash\n",
    "trimmed_data=\"4.trimmed_data\"\n",
    "labeled_data=\"9.labeled_data\"\n",
    "\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "echo Renameing sequences with \">barcodelabel=sample_id;sequence_id\"\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "mkdir ${labeled_data}\n",
    "mkdir working2\n",
    "\n",
    "#*****************************************************************************************\n",
    "# Step 1: Remove \">\" from start of sequence_ID\n",
    "\n",
    "for file7 in ${trimmed_data}/*.fasta\n",
    "    do\n",
    "\n",
    "    sed -e 's/>/>barcodelabel=;/g' ${file7} > working2/$(basename \"$file7\" .fasta).txt\n",
    "done\n",
    "\n",
    "#*****************************************************************************************\n",
    "# Step 2: Add sample_ID (should be filename) to produce \">barcodelabel=sample_ID;sequence_ID\"\n",
    "\n",
    "for file8 in working2/*.txt\n",
    "    do\n",
    "\n",
    "    sample_id=$(basename ${file8} .txt)\n",
    "    echo ${sample_id}\n",
    "\n",
    "    sed -e \"s/;/${sample_id};/g\" ${file8} > \"${labeled_data}/$(basename \"$file8\" .txt).fasta\"\n",
    "done\n",
    "\n",
    "\n",
    "#*****************************************************************************************\n",
    "# Remove working directories\n",
    "\n",
    "rm -r working2\n",
    "\n",
    "##########################################################################################\n",
    "##########################################################################################\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Removing low abundant sequences\n",
    "\n",
    "[fastx_uniques command](https://www.drive5.com/usearch/manual/cmd_fastx_uniques.html) \n",
    "\n",
    "This command finds the set of unique sequences in an input file, also called dereplication. In this case the input is a `fasta` file. Sequences are compared letter-by-letter and must be identical over the full length of both sequences (substrings do not match).\n",
    " \n",
    "[sortbysize command](https://www.drive5.com/usearch/manual/cmd_sortbysize.html) \n",
    "\n",
    "This command sorts sequences by decreasing size annotation, which usually refers to the size of a cluster. In this case we also add a `-maxsize` option to specify singletons i.e. `1`.\n",
    " \n",
    "[search_exact command](https://www.drive5.com/usearch/manual9.2/cmd_search_exact.html) This command searches for exact, full-length matches to a database sequence. This alogorithm is only available with usearch8, however even for large datasets the 32-bit version is fine as it does not need to store alot of memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```bash\n",
    "usearch=\"usearch9.2\"\n",
    "labeled_data=\"9.labeled_data\"\n",
    "derep_dir=\"10.derep_data\"\n",
    "low_abund_seqs=\"11.low_abund_sequences\"\n",
    "SF=\"12.singleton_filtered\"\n",
    "# Enter max replicate cluster size (eg. to remove singletons enter 1, for duplicates enter 2)\n",
    "maxsize=\"1\"\n",
    "\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "echo Removing low abundant seqs singletons per sample\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "echo \"\"\n",
    "\n",
    "# Creating directories\n",
    "\n",
    "mkdir ${derep_dir}\n",
    "mkdir ${low_abund_seqs}\n",
    "mkdir ${SF}\n",
    "\n",
    "#*****************************************************************************************\n",
    "# Step 1: Dereplicating\n",
    "\n",
    "for file9 in ${labeled_data}/*.fasta\n",
    "    do\n",
    "\n",
    "        echo \"\"\n",
    "        echo ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        echo Removing singletons step 1: derep_fulllength\n",
    "        echo input is:\n",
    "        echo ${file9}\n",
    "\n",
    "    $usearch -fastx_uniques ${file9} -fastaout \"${derep_dir}/$(basename \"$file9\" .fasta).fasta\" -sizeout\n",
    "done\n",
    "\n",
    "\n",
    "#*****************************************************************************************\n",
    "# Step 2: Filtering low abundant seqs {maxsize}\n",
    "\n",
    "for file10 in ${derep_dir}/*.fasta\n",
    "    do\n",
    "\n",
    "        echo \"\"\n",
    "        echo ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        echo Removing singletons step 2: sorting uniques\n",
    "        echo input is:\n",
    "        echo ${file10}\n",
    "\n",
    "    $usearch9 -sortbysize ${file10} -fastaout \"${low_abund_seqs}/$(basename \"$file10\" .fasta).fasta\" -maxsize ${maxsize}\n",
    "done\n",
    "\n",
    "#*****************************************************************************************\n",
    "# Step 3: Mapping reads\n",
    "\n",
    "for file11 in ${labeled_data}/*.fasta\n",
    "    do\n",
    "\n",
    "        echo \"\"\n",
    "        echo ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        echo Removing singletons step 3: mapping reads to low abundant uniques\n",
    "        echo input is:\n",
    "        echo ${file11}\n",
    "\n",
    "    $usearch9 -search_exact ${file11} -db \"${low_abund_seqs}/$(basename \"$file11\" .fasta).fasta\" -strand plus -notmatched \"${SF}/$(basename \"$file11\" .fasta).fasta\"\n",
    "done\n",
    "\n",
    "\n",
    "#*****************************************************************************************\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Dereplicating singleton filtered sequence\n",
    "\n",
    "Note that this leads to a dead end essentially. However is is useful if wanting to just analyse a single sample, without having to import the large concatenated sequences.\n",
    "\n",
    "[fastx_uniques command](https://www.drive5.com/usearch/manual9.2/cmd_fastx_uniques.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```bash\n",
    "usearch=\"usearch10\"\n",
    "SF=\"12.singleton_filtered\"\n",
    "SF_derep=\"13.singleton_filtered_derep\"\n",
    "\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "echo Dereplicating SF files\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "mkdir ${SF_derep}\n",
    "\n",
    "#*****************************************************************************************\n",
    "for file15 in ${SF}/*.fasta\n",
    "    do\n",
    "\n",
    "        echo \"\"\n",
    "        echo ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        echo Derep_fulllength SF data\n",
    "        echo input is:\n",
    "        echo ${file15}\n",
    "\n",
    "    $usearch -fastx_uniques ${file15} -fastaout \"${SF_derep}/$(basename \"$file15\" .fasta).fasta\" -sizeout\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Clustering\n",
    "\n",
    "This step is where you may encounter issues with enough memory, for 1 or 2 MiSeq runs, the 32-bit versions of usearch may be okay, however any larger and you will need to use the 64-bit, paid versions. There are alternative freely available software for this step such as vsearch, and it may be worth your time exploring these options if you encounter such limits. For this case we will assume you either have a small data set or have access to the 64-bit versions for larger datasets.\n",
    "\n",
    "There are two main alogorithms we recommend you do both and see what works. In my opinion I think that uparse OTUs are sufficent for 16S microbiome analysis in _most_ cases. However if you are after more specific information (i.e. genotypes) or perhaps you targeted a more specific gene region (i.e. your primer were genus/family specific), you may want to go with ZOTUs. In short I think you should do both and make the descision of which makes biological sense in your study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UPARSE algorithm to generate OTUs\n",
    "\n",
    "The UPARSE algorithm is available in usearch 9.2 and usearch 10. If you have a large dataset you will need the 64-bit version as it does hold memory. Detailed documentation on this algorithm can be found [here](https://drive5.com/usearch/manual/uparseotu_algo.html).\n",
    "\n",
    "The UPARSE-OTU algorithm constructs a set of OTU representative sequences from NGS amplicon reads. R\n",
    "\n",
    "Clustering criteria\n",
    "The goal of UPARSE-OTU is to identify a set of OTU representative sequences (a subset of the input sequences) satisfying the following criteria.\n",
    "\n",
    "1. All pairs of OTU sequences should have < 97% pair-wise sequence identity.\n",
    "2. An OTU sequence should be the most abundant within a 97% neighborhood.\n",
    "3. Chimeric sequences should be discarded.\n",
    "4. All non-chimeric input sequences should match at least one OTU with ≥ 97% identity.\n",
    "\n",
    "UPARSE-OTU uses a greedy algorithm to find a biologically relevant solution, as follows. Since high-abundance reads are more likely to be correct amplicon sequences, and hence are more likely to be true biological sequences, UPARSE-OTU considers input sequences in order of decreasing abundance. This means that OTU centroids tend to be selected from the more abundant reads, and hence are more likely to be correct biological sequences.\n",
    "\n",
    "**Reference**<br></br>\n",
    "Edgar, R.C. (2013) UPARSE: Highly accurate OTU sequences from microbial amplicon reads, Nature Methods.<br></br>\n",
    "[Pubmed:23955772, dx.doi.org/10.1038/nmeth.2604](https://www.nature.com/articles/nmeth.2604)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "SF=\"12.singleton_filtered\"\"\n",
    "cluster=\"13.cluster\"\n",
    "uparse_otus=\"13a.otus\"\n",
    "usearch=\"usearch9.2\"\n",
    "\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "echo UPARSE on all\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "mkdir ${cluster}\n",
    "\n",
    "    cat ${SF}/*.fasta > uparse_all/all_samples_SF.fasta\n",
    "\n",
    "cd ${cluster}\n",
    "\n",
    "mkdir ${uparse_otus}\n",
    "cd ${uparse_otus}\n",
    "\n",
    "$usearch -fastx_uniques ../all_samples_SF.fasta -fastaout all_samples_SF_DR.fasta -sizeout\n",
    "\n",
    "$usearch -cluster_otus all_samples_SF_DR.fasta -otus uparse_otus.fasta -relabel OTU\n",
    "\n",
    "$usearch -usearch_global all_samples_SF.fasta -db uparse_otus.fasta -strand both -id 0.97 -otutabout uparse_otu_tab.txt -biomout uparse_otu_biom.biom\n",
    "\n",
    "$usearch -cluster_agg uparse_otus.fasta -treeout uparse_otus.tree -clusterout clusters.txt\n",
    "\n",
    "cd ..\n",
    "cd ..\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### UNOISE3 algorithm to generate ZOTUs\n",
    "\n",
    "The UNOISE3 algorithm is only availed on usearch10. If you have a large data set you will need the 64-bit version as it does hold memory. Detailed documation on this algorithm can be found [here](https://drive5.com/usearch/manual/cmd_unoise3.html).\n",
    "\n",
    "There is a UNOISE2 option in Usearch9.2 with documentation available [here](https://www.drive5.com/usearch/manual9.2/unoise_pipeline.html). \n",
    "\n",
    "This algorithm is specifically designed for Illumina sequences.\n",
    "\n",
    "The UNOISE3 algorithm performs error-correction (denoising) on amplicon reads. It is implemented in the unoise3 command.\n",
    "\n",
    "Correct biological sequences are recovered from the reads, resolving distinct sequences down to a single difference (often) or two or more differences (almost always).\n",
    "\n",
    "Errors are corrected as follows:\n",
    "1. Reads with sequencing and PCR point error are identified and removed.\n",
    "2. Chimeras are removed.\n",
    "\n",
    "**Reference**<br></br>\n",
    "Edgar, R.C. (2016), UNOISE2: Improved error-correction for Illumina 16S and ITS amplicon reads.[http://dx.doi.org/10.1101/081257](https://www.biorxiv.org/content/early/2016/10/15/081257)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "SF=\"12.singleton_filtered\"\"\n",
    "cluster=\"13.cluster\"\n",
    "unoise_zotus=\"13b.zotus\"\n",
    "# Remember is must be Usearch 10 for the unoise3 algorithm\n",
    "usearch=\"usearch10\"\n",
    "\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "echo UNOISE on all\n",
    "echo %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "mkdir ${cluster}\n",
    "\n",
    "cat ${SF}/*.fasta > ${cluster}/all_samples_SF.fasta\n",
    "\n",
    "cd ${cluster}\n",
    "\n",
    "mkdir ${unoise_zotus}\n",
    "cd ${unoise_zotus}\n",
    "\n",
    "$usearch -fastx_uniques ../all_SF.fasta -fastaout all_samples_SF_DR.fasta -sizeout\n",
    "\n",
    "$usearch -unoise3 all_samples_SF_DR.fasta -zotus unoise_zotus.fasta -tabbedout unoise_tab.txt\n",
    "\n",
    "$usearch -fastx_relabel unoise_zotus.fasta -prefix Otu -fastaout unoise_zotus_relabelled.fasta -keep_annots\n",
    "\n",
    "$usearch -otutab all_samples_SF_DR.fasta -zotus unoise_zotus_relabelled.fasta -otutabout unoise_otu_tab.txt -biomout unoise_otu_biom.biom -mapout unoise_map.txt -notmatched unoise_notmatched.fasta -dbmatched dbmatches.fasta -sizeout\n",
    "\n",
    "$usearch -cluster_agg unoise_zotus_relabelled.fasta -treeout unoise_zotusb.tree -clusterout clusters.txt -id 0.80 -linkage min\n",
    "\n",
    "cd ..\n",
    "cd ..\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next?\n",
    "\n",
    "This is downstream analysis that can done with usearch.\n",
    "For example, [taxonomy assignment](https://drive5.com/usearch/manual/cmds_taxonomy.html) and [diversity analysis](https://drive5.com/usearch/manual/cmds_div.html).\n",
    "\n",
    "However, at present there are more robust taxonomy assignment options available (such as that in QIIME2), that are easier to use. \n",
    "With respect to diversity analysis, QIIME2 and R packages such as Phyloseq and Microbiome offer much more flexibility, robustness and are more aesthectically pleasing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
